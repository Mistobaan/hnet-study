{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca5fe09",
   "metadata": {},
   "source": [
    "# Understanding H-Nets from the ground up\n",
    "\n",
    "H-Net's core idea is a novel dynamic chunking (DC) mechanism which interfaces between the main  network and the encoder/decoder networks, learning how to segment data while using standard differentiable optimization.\n",
    "\n",
    "The input is a sequence of bytes. The Encoder is a neural network (i.e. SSM Mamba) that encodes the input sequence into a sequence of latent vectors. The Decoder is another neural network (i.e. SSM Mamba) that decodes the latent vectors back into the original sequence.\n",
    "\n",
    "Two main modules\n",
    "- routing module + downsampler (encoding)\n",
    "- smoothing module + upsampler (decoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba508066",
   "metadata": {},
   "source": [
    "$$ x^0 \\in \\mathbb{R}^{L^0 \\times D^0} $$\n",
    "$$ p^0 \\in [0, 1]^{L^0 } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de0be1",
   "metadata": {},
   "source": [
    "Encoder:\n",
    "$$ \\hat{x}^0 = \\mathcal{E}^0 (x^0) $$\n",
    "Chunker:\n",
    "$$ (x^{1}, p^0) = \\operatorname{Chunk}(\\hat{x}^0) $$\n",
    "Main Neural Network:\n",
    "$$ \\hat{z}^0 = \\mathcal{M}(x^0) $$\n",
    "Dechunker:\n",
    "$$ z^0 = \\operatorname{Dechunk}(\\hat{z}^{1}, p^0) + \\operatorname{Linear}(\\hat{x}^0) $$\n",
    "Decoder:\n",
    "$$ \\hat{z}^0 = \\mathcal{D}^0 (z^0) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d2ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1695cf6",
   "metadata": {},
   "source": [
    "## Chunking Layer\n",
    "\n",
    "The Chunking Layer contains a routing module that computes the chunking probabilities and a downsampler that applies these probabilities to the input data.\n",
    "\n",
    "$$ q_t = W_q \\hat{x}_t, \\quad k_t = W_k \\hat{x}_t, \\quad p_t = \\frac{1}{2} \\left( 1 - \\frac{q_t^T\n",
    " k_{t-1}}{\\| q_t \\| \\| k_{t-1} \\|} \\right) \\in [0,1], \\quad b_t = 1_{\\{ p_t \\geq 0.5 \\}}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87712c02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79549064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityRouter(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(dim, dim, bias=False)\n",
    "        self.W_k = nn.Linear(dim, dim, bias=False)\n",
    "\n",
    "    def forward(self, x_hat):\n",
    "        # x_hat: (batch size, sequence length, embedding dimension) (B, L, D)\n",
    "        q = self.W_q(x_hat)  # (B, L, D)\n",
    "        k = self.W_k(x_hat)  # (B, L, D)\n",
    "\n",
    "        # Shift k to compare with previous\n",
    "        # k_{t-1} for t=1 is k_1 (paper sets p_1=1)\n",
    "        k_shifted = torch.cat([k[:, :1, :],\n",
    "                               k[:, :-1, :]],\n",
    "                               dim=1)\n",
    "\n",
    "        # Cosine similarity: q_t^T k_{t-1} / (|q_t| |k_{t-1}|)\n",
    "        dot = torch.sum(q * k_shifted, dim=-1)  # (B, L)\n",
    "        norm_q = torch.norm(q, dim=-1) + 1e-8\n",
    "        norm_k = torch.norm(k_shifted, dim=-1) + 1e-8\n",
    "        cos_sim = dot / (norm_q * norm_k)\n",
    "\n",
    "        # p_t = 1/2 (1 - cos_sim)\n",
    "        p = 0.5 * (1 - cos_sim)  # (B, L)\n",
    "        p[:, 0] = 1.0  # Force p_1 = 1.0\n",
    "\n",
    "        # Boundary indicators b_t = 1 if p_t >= 0.5\n",
    "        b = (p >= 0.5).float()  # (B, L)\n",
    "\n",
    "        return p, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f845cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x_hat, b, p):\n",
    "    # x_hat: (B, L, D), b: (B, L), p: (B, L)\n",
    "    # Find positions where b_t == 1\n",
    "    mask = b.bool()  # (B, L)\n",
    "\n",
    "    # Compressed x_next: gather elements where mask is True\n",
    "    # For each batch, collect non-zero indices\n",
    "    x_next = []\n",
    "    P_next = []\n",
    "    for i in range(x_hat.shape[0]):\n",
    "        idx = mask[i].nonzero(as_tuple=False).squeeze(-1)  # Indices where b=1\n",
    "        x_next.append(x_hat[i, idx, :])\n",
    "        P_next.append(p[i, idx])\n",
    "\n",
    "    # Pad to max length for batching (in practice, use variable length or padding)\n",
    "    max_len = max(len(x) for x in x_next)\n",
    "    x_next_padded = torch.stack([F.pad(x, (0, 0, 0, max_len - len(x))) for x in x_next])\n",
    "    P_next_padded = torch.stack([F.pad(P, (0, max_len - len(P))) for P in P_next])\n",
    "\n",
    "    return x_next_padded, P_next_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762f4cf",
   "metadata": {},
   "source": [
    "## Dechunker \n",
    "\n",
    "The Dechunker consists of a smoothing module:\n",
    "\n",
    "$$ z^s = \\operatorname{Dechunk}(\\hat{z}^{s+1}, p^s) + \\operatorname{Linear}(\\hat{x}^s). $$\n",
    "\n",
    "The critical challenge in training a dynamic chunking module lies in the *discrete nature* of chunk  boundaries, which impedes gradient flow during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_module(z_hat, P):\n",
    "    # z_hat: (B, L_compressed, D), P: (B, L_compressed)\n",
    "    # exponential moving average smoothing\n",
    "    bar_z = torch.zeros_like(z_hat)\n",
    "    for b in range(z_hat.shape[0]):\n",
    "        bar_z[b, 0] = z_hat[b, 0]\n",
    "        for t in range(1, z_hat.shape[1]):\n",
    "            bar_z[b, t] = P[b, t] * z_hat[b, t] + (1 - P[b, t]) * bar_z[b, t-1]\n",
    "    return bar_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cecaf",
   "metadata": {},
   "source": [
    "### Dechunker 2/2: Upsampler. \n",
    "\n",
    "We carefully design the upsampler that decompresses $\\hat{z}^{s+1}$ to match \n",
    "the original resolution of inputs in the previous stage $z^s$ with the \n",
    "following definition:\n",
    "\n",
    "$$\n",
    "c_t = p_t^{b_t} (1 - p_t)^{1 - b_t} = \n",
    "\\begin{cases} \n",
    "p_t & \\text{if } b_t = 1, \\\\ \n",
    "1 - p_t & \\text{otherwise},\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{STE}(c_t) = c_t + \\text{stopgradient}(1 - c_t),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{z}_t = \\tilde{z}_{\\sum_{k=1}^t b_k},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Upsampler}(\\tilde{z}, c)_t = \\text{STE} (c_t ) \\cdot \\tilde{z}_t.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42480e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(bar_z, b, p, original_L, D):\n",
    "    # bar_z: (B, L_compressed, D), b: (B, original_L), p: (B, original_L)\n",
    "    z = torch.zeros(bar_z.shape[0], original_L, D, device=bar_z.device)\n",
    "\n",
    "    for i in range(bar_z.shape[0]):\n",
    "        chunk_idx = 0\n",
    "        for t in range(original_L):\n",
    "            z[i, t] = bar_z[i, chunk_idx]\n",
    "            if b[i, t] == 1 and t < original_L - 1:  # Move to next chunk at boundary\n",
    "                chunk_idx += 1\n",
    "\n",
    "    # Confidence adjustment (from paper: c_t = p_t^{b_t} (1-p_t)^{1-b_t})\n",
    "    c = p.clone()\n",
    "    c[b == 1] = p[b == 1]\n",
    "    c[b == 0] = 1 - p[b == 0]\n",
    "    # Not directly used in dechunk, perhaps for weighting; here we skip for simplicity\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e493d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HNet(nn.Module):\n",
    "    def __init__(self, dim, num_stages=1):\n",
    "        super().__init__()\n",
    "        self.num_stages = num_stages\n",
    "        self.router = SimilarityRouter(dim)\n",
    "        self.encoder = nn.Linear(dim, dim)  # Placeholder for E_s (e.g., Mamba layer)\n",
    "        self.main = nn.Linear(dim, dim)     # Placeholder for M\n",
    "        self.decoder = nn.Linear(dim, dim)  # Placeholder for D_s\n",
    "        self.linear_skip = nn.Linear(dim, dim)  # For skip connection\n",
    "\n",
    "    def forward(self, x0):\n",
    "        # x0: (B, L0, D0)\n",
    "        xs = [x0]\n",
    "        ps = []\n",
    "\n",
    "        # Forward: Encode and Chunk (compress)\n",
    "        for s in range(self.num_stages):\n",
    "            x_hat = self.encoder(xs[-1])\n",
    "            p, b = self.router(x_hat)\n",
    "            x_next, P_next = downsample(x_hat, b, p)\n",
    "            xs.append(x_next)\n",
    "            ps.append((p, b, P_next))\n",
    "\n",
    "        # Main network at final stage\n",
    "        z_hat_S = self.main(xs[-1])\n",
    "        zs = [z_hat_S]\n",
    "\n",
    "        # Backward: Dechunk and Decode (decompress)\n",
    "        for s in reversed(range(self.num_stages)):\n",
    "            bar_z = ema_smooth(zs[-1], ps[s][2])  # P_next\n",
    "            z_s = upsample(bar_z, ps[s][1], ps[s][0], xs[s].shape[1], xs[s].shape[2])\n",
    "            z_s += self.linear_skip(self.encoder(xs[s]))  # Skip connection\n",
    "            z_hat_s = self.decoder(z_s)\n",
    "            zs.append(z_hat_s)\n",
    "\n",
    "        return zs[-1]  # Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe134d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 525 is out of bounds for dimension 1 with size 525",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m model = HNet(dim, num_stages=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m x = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m1024\u001b[39m, dim)  \u001b[38;5;66;03m# Batch 1, seq len 1024, dim 512\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output = model(x)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(output.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mHNet.forward\u001b[39m\u001b[34m(self, x0)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_stages)):\n\u001b[32m     30\u001b[39m     bar_z = ema_smooth(zs[-\u001b[32m1\u001b[39m], ps[s][\u001b[32m2\u001b[39m])  \u001b[38;5;66;03m# P_next\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     z_s = upsample(bar_z, ps[s][\u001b[32m1\u001b[39m], ps[s][\u001b[32m0\u001b[39m], xs[s].shape[\u001b[32m1\u001b[39m], xs[s].shape[\u001b[32m2\u001b[39m])\n\u001b[32m     32\u001b[39m     z_s += \u001b[38;5;28mself\u001b[39m.linear_skip(\u001b[38;5;28mself\u001b[39m.encoder(xs[s]))  \u001b[38;5;66;03m# Skip connection\u001b[39;00m\n\u001b[32m     33\u001b[39m     z_hat_s = \u001b[38;5;28mself\u001b[39m.decoder(z_s)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mupsample\u001b[39m\u001b[34m(bar_z, b, p, original_L, D)\u001b[39m\n\u001b[32m     15\u001b[39m chunk_idx = \u001b[32m0\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(original_L):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     z[i, t] = bar_z[i, chunk_idx]\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m b[i, t] == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m t < original_L - \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# Move to next chunk at boundary\u001b[39;00m\n\u001b[32m     19\u001b[39m         chunk_idx += \u001b[32m1\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: index 525 is out of bounds for dimension 1 with size 525"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "dim = 512\n",
    "model = HNet(dim, num_stages=1)\n",
    "x = torch.randn(1, 1024, dim)  # Batch 1, seq len 1024, dim 512\n",
    "output = model(x)\n",
    "print(output.shape)  # Should be (1, 1024, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209c697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
